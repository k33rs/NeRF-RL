{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from nerfstudio.cameras.camera_paths import get_interpolated_camera_path\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "import numpy as np\n",
    "import src.ddpg as ddpg\n",
    "import src.sac as sac\n",
    "import src.shared as shared\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(f'nerfstudio/lego/nerfacto/2024-05-02_094606/config-down-x{downscale}.yml')\n",
    "db_path = f'nerfstudio/db-x{downscale}.pkl'\n",
    "\n",
    "_, pipeline, _, _ = eval_setup(config_path, test_mode='val')\n",
    "\n",
    "train_dataset = pipeline.datamanager.train_dataset\n",
    "eval_dataset = pipeline.datamanager.eval_dataset\n",
    "model = pipeline.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-render NeRF\n",
    "try:\n",
    "    db = torch.load(db_path)\n",
    "except:\n",
    "    train_loader = shared.CustomDL(train_dataset.cameras, device=device)\n",
    "    test_loader = shared.CustomDL(eval_dataset.cameras, device=device)\n",
    "\n",
    "    db = dict()\n",
    "    shared.nerf.pre_render(model, train_loader, db)\n",
    "    shared.nerf.pre_render(model, test_loader, db)\n",
    "    torch.save(db, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch image size\n",
    "db0 = db[list(db.keys())[0]]\n",
    "imsize = db0['imsize']\n",
    "imshape = db0['imshape']\n",
    "f'imsize = {imsize}, imshape = {imshape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_nerf = shared.nerf.CustomNeRF(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dist_mat = torch.load('nerfstudio/dist_mat.pkl')\n",
    "except:\n",
    "    dl1 = shared.CustomDL(train_dataset.cameras, device=device)\n",
    "    dl2 = shared.CustomDL(train_dataset.cameras, device=device)\n",
    "\n",
    "    dist_mat = torch.full((len(dl1), len(dl2)), torch.inf)\n",
    "\n",
    "    for i, rb1 in enumerate(dl1):\n",
    "        oi = rb1.origins[0]\n",
    "        dl2.reset(dl1.step)\n",
    "\n",
    "        for j, rb2 in enumerate(dl2, start=i+1):\n",
    "            display(f'{i} {j}')\n",
    "            clear_output(wait=True)\n",
    "            oj = rb2.origins[0]\n",
    "\n",
    "            dist = (oi - oj).norm().item()\n",
    "            dist_mat[i, j] = dist\n",
    "\n",
    "    torch.save(dist_mat, 'nerfstudio/dist_mat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort camera pairs by ascending distance\n",
    "k = 6800\n",
    "\n",
    "dist_flat = dist_mat.flatten()\n",
    "top_val, idx_flat = dist_flat.topk(k, largest=False)\n",
    "\n",
    "row_idx = idx_flat // dist_mat.size(1)\n",
    "col_idx = idx_flat % dist_mat.size(1)\n",
    "top_idx = torch.stack((row_idx, col_idx), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_idx, top_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1: far vs close camera pair\n",
    "idx = 43 # 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 155 # 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 560 # 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1995 # 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6786 # 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_idx[idx], top_val[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pair = train_dataset.cameras[top_idx[idx]]\n",
    "camera_interpol = get_interpolated_camera_path(camera_pair, steps=3, order_poses=True)[1:2]\n",
    "\n",
    "train_loader = shared.CustomDL(camera_pair, step_size=len(camera_pair), device=device, disable_distortion=True)\n",
    "test_loader = shared.CustomDL(camera_interpol, step_size=len(camera_interpol), device=device, disable_distortion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPG\n",
    "config = ddpg.Config(\n",
    "    warmup=5000,\n",
    "    max_steps=True,\n",
    "    eval_episodes=1,\n",
    ")\n",
    "\n",
    "rad_thres = .5\n",
    "rad_goal = .5\n",
    "\n",
    "env = shared.env.NerfEnv(\n",
    "    custom_nerf,\n",
    "    rad_thres=rad_thres,\n",
    "    rad_goal=rad_goal,\n",
    "    reward_scale=10,\n",
    "    reward_max_resolution=4,\n",
    "    obscure=True,\n",
    ")\n",
    "\n",
    "runner = ddpg.Runner(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    env,\n",
    "    config,\n",
    "    tensorboard=True,\n",
    "    with_img=True,\n",
    "    # save_path='out/ddpg-0.06',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAC\n",
    "config = sac.Config(\n",
    "    warmup=1000,\n",
    "    mem_batch_size=256,\n",
    "    max_steps=True,\n",
    "    eval_episodes=1,\n",
    ")\n",
    "\n",
    "rad_thres = .5\n",
    "rad_goal = .5\n",
    "\n",
    "env = shared.env.NerfEnv(\n",
    "    custom_nerf,\n",
    "    rad_thres=rad_thres,\n",
    "    rad_goal=rad_goal,\n",
    "    reward_scale=10,\n",
    "    reward_max_resolution=4,\n",
    ")\n",
    "\n",
    "runner = sac.Runner(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    env,\n",
    "    config,\n",
    "    tensorboard=True,\n",
    "    with_img=True,\n",
    "    # save_path='out/sac-0.06',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.env.model = model\n",
    "runner.test_loader.random_rays = False\n",
    "\n",
    "intgr = runner(mode='test', load_weights={\n",
    "    'actor': f'{runner.save_path}/actor.pkl',\n",
    "    'critic': f'{runner.save_path}/critic.pkl'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loader = shared.CustomDL(camera_pair, step_size=2, device=device, disable_distortion=True)\n",
    "fname = 'camera-pose'\n",
    "goal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'camera-pose-goal'\n",
    "goal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loader = shared.CustomDL(camera_interpol, step_size=1, device=device, disable_distortion=True)\n",
    "fname = 'interpol'\n",
    "goal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'interpol-goal'\n",
    "goal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rb in plot_loader:\n",
    "    rb.directions = shared.geom.camera_to_world(rb.directions, rb.camera_to_world) - rb.origins\n",
    "    out = model(rb)\n",
    "    rgb = out['rgb']\n",
    "    gs = rgb.mean(dim=-1)\n",
    "    if goal:\n",
    "        gs[gs < rad_goal] = 0\n",
    "    img = gs.reshape(-1, *rb.imshape).detach().cpu().numpy()\n",
    "    shared.utils.show_img(img, title=fname, stdout=True, write_path=runner.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical test: naive Monte Carlo\n",
    "test_loader.random_rays = True\n",
    "\n",
    "iters = 1500\n",
    "integrals = []\n",
    "\n",
    "for _ in range(iters):\n",
    "    for rb in test_loader:\n",
    "        # convert from camera to world coords\n",
    "        rb.directions = shared.geom.camera_to_world(\n",
    "            rb.directions,\n",
    "            rb.camera_to_world,\n",
    "        ) - rb.origins\n",
    "\n",
    "        out = model(rb)\n",
    "        rgb = out['rgb']\n",
    "        gs = rgb.mean(dim=-1).detach().cpu().numpy()\n",
    "\n",
    "        goal = gs[gs >= rad_thres]\n",
    "        size = goal.shape[0]\n",
    "\n",
    "        intgr = (goal * size).mean()\n",
    "        integrals.append(intgr)\n",
    "\n",
    "integrals = np.array(integrals)\n",
    "print(f'mean = {integrals.mean()}, std = {integrals.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical test: DDPG\n",
    "runner.evaluator.tensorboard = False\n",
    "runner.evaluator.with_img = False\n",
    "runner.test_loader.random_rays = True\n",
    "weights = {\n",
    "    'actor': f'{runner.save_path}/actor.pkl',\n",
    "    'critic': f'{runner.save_path}/critic.pkl'\n",
    "}\n",
    "\n",
    "iters = 10\n",
    "integrals = []\n",
    "\n",
    "for _ in range(iters):\n",
    "    intgr = runner(mode='test', load_weights=weights, with_penalty=True)\n",
    "    integrals.append(intgr)\n",
    "\n",
    "integrals = np.array(integrals)\n",
    "print(f'mean = {integrals.mean()}, std = {integrals.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 2: camera with 3 neighbors (at different distances)\n",
    "idx = torch.where(top_idx[:, 0] == top_idx[3, 0])[0]\n",
    "idx_lst = list(set(top_idx[idx].flatten().tolist()))\n",
    "idx_lst.remove(top_idx[3, 0].item())\n",
    "train_idx = torch.tensor(idx_lst)\n",
    "test_idx = top_idx[3, 0].unsqueeze(-1)\n",
    "\n",
    "camera_train = train_dataset.cameras[train_idx]\n",
    "camera_test = train_dataset.cameras[test_idx]\n",
    "\n",
    "top_idx[idx], top_val[idx], train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = shared.CustomDL(camera_train, step_size=len(train_idx), device=device)\n",
    "test_loader = shared.CustomDL(camera_test, step_size=len(test_idx), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loader = shared.CustomDL(camera_train, step_size=len(train_idx), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loader = shared.CustomDL(camera_test, step_size=len(test_idx), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rb in plot_loader:\n",
    "    directions = rb.directions.clone()\n",
    "    rb.directions = shared.geom.camera_to_world(rb.directions, rb.camera_to_world) - rb.origins\n",
    "    out = custom_nerf(rb)\n",
    "    ref = model(rb)\n",
    "    rb.directions = directions\n",
    "    rgb1 = out['rgb']\n",
    "    gs1 = rgb1.mean(dim=-1)\n",
    "    img1 = gs1.reshape(rgb1.shape[0] // rb.imsize, *rb.imshape).detach().cpu().numpy()\n",
    "    shared.utils.show_img(img1, title='bilinear interpolation', stdout=True)\n",
    "    rgb2 = ref['rgb']\n",
    "    gs2 = rgb2.mean(dim=-1)\n",
    "    img2 = gs2.reshape(rgb2.shape[0] // rb.imsize, *rb.imshape).detach().cpu().numpy()\n",
    "    shared.utils.show_img(img2, title='NeRF', stdout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire dataset\n",
    "train_loader = shared.CustomDL(train_dataset.cameras, step_size=10, device=device)\n",
    "test_loader = shared.CustomDL(eval_dataset.cameras, step_size=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
